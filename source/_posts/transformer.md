---
title: transformer
date: 2023-03-09 17:09:22
tags: NLP
katex: true
---
### 簡單來說
輸入 -> Encoding -> Decoding -> 輸出

### 原理
#### 總覽
<img src="..\transformer\model.jpg" height=250ppt>

#### Self-Attention
<img src="..\transformer\20150622OMcuB9Q8Zl.jpg">

Q : 原物
K : 相似參數
Q dot K : 相似度(attan)

#### Add & Norm
<img src="..\transformer\20129616BHmGH4ukte.png">

1. Residual
2. LayerNorm 


