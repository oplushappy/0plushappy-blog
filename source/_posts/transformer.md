---
title: Transformer
tags: NLP
katex: true
abbrlink: e0d2147a
date: 2023-03-09 17:09:22
---
### 簡單來說
輸入 -> Encoding -> Decoding -> 輸出

### 原理
#### 總覽
![this is jpg](transformer/model.jpg)

#### Self-Attention

![this is jpg](transformer/20150622OMcuB9Q8Zl.jpg)


Q : 原物
K : 相似參數
Q dot K : 相似度(attan)

#### Add & Norm

![](transformer/20129616BHmGH4ukte.png)

1. Residual
2. LayerNorm 


